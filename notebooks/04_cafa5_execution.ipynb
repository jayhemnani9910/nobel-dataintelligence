{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f482a8bf",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985282bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.multimodal import VibroStructuralModel\n",
    "from models.losses import FocalLoss, WeightedBCELoss\n",
    "from datasets import CAFA5Dataset, create_dataloaders\n",
    "from training import Trainer, MetricComputer, create_training_config\n",
    "from data_acquisition import KaggleDataAcquisition\n",
    "from utils import Logger, set_seed, get_device\n",
    "\n",
    "# Setup\n",
    "logger = Logger.setup('QDD-CAFA5', level=logging.INFO)\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Create directories\n",
    "Path('./data/cafa5').mkdir(parents=True, exist_ok=True)\n",
    "Path('./data/pdb_structures').mkdir(parents=True, exist_ok=True)\n",
    "Path('./checkpoints').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c509504",
   "metadata": {},
   "source": [
    "## 2. Download and Explore CAFA 5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b40e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CAFA 5 data\n",
    "logger.info(\"Downloading CAFA 5 competition data...\")\n",
    "kaggle_acq = KaggleDataAcquisition(output_dir=\"./data/cafa5\")\n",
    "\n",
    "# Note: Uncomment to download\n",
    "# train_terms, test_seqs, go_annot = kaggle_acq.download_cafa5()\n",
    "\n",
    "# For this demo, check if files exist\n",
    "train_terms_file = Path('./data/cafa5/train_terms.csv')\n",
    "test_seqs_file = Path('./data/cafa5/test_sequences.fasta')\n",
    "go_vocab_file = Path('./data/cafa5/go_vocabulary.csv')\n",
    "\n",
    "if not train_terms_file.exists():\n",
    "    logger.warning(\"CAFA 5 data not found. Please run: kaggle competitions download -c cafa-5-protein-function-prediction -p ./data/cafa5\")\n",
    "else:\n",
    "    logger.info(\"CAFA 5 data found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfed7bc",
   "metadata": {},
   "source": [
    "## 3. Load and Explore GO Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training terms\n",
    "try:\n",
    "    df_terms = pd.read_csv('./data/cafa5/train_terms.csv')\n",
    "    logger.info(f\"Training terms shape: {df_terms.shape}\")\n",
    "    logger.info(f\"\\nFirst few rows:\")\n",
    "    print(df_terms.head(10))\n",
    "    \n",
    "    logger.info(f\"\\nData info:\")\n",
    "    print(df_terms.info())\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"train_terms.csv not found. Using demo data structure.\")\n",
    "    df_terms = pd.DataFrame({\n",
    "        'protein_id': [f'protein_{i}' for i in range(1000)],\n",
    "        'go_term': [f'GO:{np.random.randint(1000000, 9999999):07d}' for _ in range(1000)]\n",
    "    })\n",
    "    logger.info(f\"Demo dataset created: {df_terms.shape[0]} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GO term distribution\n",
    "logger.info(\"Analyzing GO term distribution...\")\n",
    "\n",
    "# Count unique proteins and terms\n",
    "n_proteins = df_terms['protein_id'].nunique()\n",
    "n_go_terms = df_terms['go_term'].nunique()\n",
    "n_annotations = len(df_terms)\n",
    "\n",
    "logger.info(f\"Unique proteins: {n_proteins:,}\")\n",
    "logger.info(f\"Unique GO terms: {n_go_terms:,}\")\n",
    "logger.info(f\"Total annotations: {n_annotations:,}\")\n",
    "logger.info(f\"Avg terms per protein: {n_annotations / n_proteins:.2f}\")\n",
    "\n",
    "# Analyze term frequency\n",
    "term_counts = df_terms['go_term'].value_counts()\n",
    "logger.info(f\"\\nGO term frequency:\")\n",
    "logger.info(f\"  Max: {term_counts.max()}\")\n",
    "logger.info(f\"  Min: {term_counts.min()}\")\n",
    "logger.info(f\"  Median: {term_counts.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be23c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GO distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Top GO terms\n",
    "top_go = df_terms['go_term'].value_counts().head(15)\n",
    "axes[0].barh(range(len(top_go)), top_go.values, color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_go)))\n",
    "axes[0].set_yticklabels(top_go.index, fontsize=9)\n",
    "axes[0].set_xlabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Top 15 Most Frequent GO Terms', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Terms per protein distribution\n",
    "terms_per_protein = df_terms.groupby('protein_id').size()\n",
    "axes[1].hist(terms_per_protein, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Number of GO Terms', fontsize=11)\n",
    "axes[1].set_ylabel('Number of Proteins', fontsize=11)\n",
    "axes[1].set_title('GO Terms per Protein Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"GO analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2ab29",
   "metadata": {},
   "source": [
    "## 4. Create GO Term Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build GO vocabulary\n",
    "logger.info(\"Building GO term vocabulary...\")\n",
    "\n",
    "unique_go_terms = sorted(df_terms['go_term'].unique())\n",
    "go_to_idx = {go: idx for idx, go in enumerate(unique_go_terms)}\n",
    "idx_to_go = {idx: go for go, idx in go_to_idx.items()}\n",
    "\n",
    "logger.info(f\"Vocabulary size: {len(go_to_idx)} GO terms\")\n",
    "logger.info(f\"\\nSample terms:\")\n",
    "for i, go_term in enumerate(unique_go_terms[:10]):\n",
    "    idx = go_to_idx[go_term]\n",
    "    count = (df_terms['go_term'] == go_term).sum()\n",
    "    logger.info(f\"  {idx}: {go_term} (n={count})\")\n",
    "\n",
    "# Save vocabulary\n",
    "vocab_df = pd.DataFrame({\n",
    "    'go_term': unique_go_terms,\n",
    "    'index': [go_to_idx[go] for go in unique_go_terms]\n",
    "})\n",
    "vocab_df.to_csv('./data/cafa5/go_vocabulary.csv', index=False)\n",
    "logger.info(f\"\\nVocabulary saved to go_vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d29253",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5799e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CAFA 5 dataset\n",
    "logger.info(\"Creating CAFA 5 dataset...\")\n",
    "\n",
    "try:\n",
    "    dataset = CAFA5Dataset(\n",
    "        terms_file='./data/cafa5/train_terms.csv',\n",
    "        sequences_file='./data/cafa5/test_sequences.fasta',\n",
    "        structures_dir='./data/pdb_structures',\n",
    "        vocab_file='./data/cafa5/go_vocabulary.csv'\n",
    "    )\n",
    "    logger.info(f\"Dataset created: {len(dataset)} proteins\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"CAFA5Dataset creation failed: {e}\")\n",
    "    logger.info(\"Using demo dataset...\")\n",
    "    dataset = None\n",
    "\n",
    "if dataset is not None:\n",
    "    # Split into train/val/test\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Split: train={train_size}, val={val_size}, test={test_size}\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    \n",
    "    logger.info(\"DataLoaders created successfully!\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: skipping DataLoader creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60b047",
   "metadata": {},
   "source": [
    "## 6. Initialize Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a8a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "logger.info(\"Initializing Vibro-Structural model for multi-label classification...\")\n",
    "\n",
    "num_go_terms = len(go_to_idx) if dataset is not None else 10000\n",
    "\n",
    "model = VibroStructuralModel(\n",
    "    latent_dim=128,\n",
    "    gnn_input_dim=24,\n",
    "    fusion_type='bilinear',\n",
    "    dropout=0.2,\n",
    "    num_go_terms=num_go_terms\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Model: {total_params:,} total parameters, {trainable_params:,} trainable\")\n",
    "logger.info(f\"Output dimension: {num_go_terms} GO terms\")\n",
    "\n",
    "# Setup training\n",
    "optimizer = Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Use weighted BCE for class imbalance in GO term prediction\n",
    "# Focal loss is alternative (uncomment to use)\n",
    "loss_fn = WeightedBCELoss(weight=2.0)  # Up-weight positive examples\n",
    "# loss_fn = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    checkpoint_dir='./checkpoints'\n",
    ")\n",
    "\n",
    "logger.info(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7730ec",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (requires actual dataset)\n",
    "if dataset is not None:\n",
    "    logger.info(\"Starting training...\")\n",
    "    logger.info(f\"Task: Multi-label GO term prediction ({num_go_terms} terms)\")\n",
    "    logger.info(f\"Metric: F-max score (optimized F1)\")\n",
    "    \n",
    "    best_loss = trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=100,\n",
    "        metric_fn=MetricComputer.f_max_score,\n",
    "        early_stopping_patience=15,\n",
    "        task='cafa5'\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"\\nTraining complete! Best validation loss: {best_loss:.4f}\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: Training skipped. Use actual CAFA 5 data to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5985a4",
   "metadata": {},
   "source": [
    "## 8. Evaluate with F-max Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is not None:\n",
    "    logger.info(\"Evaluating on test set with F-max metric...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds_prob = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            graph = batch['graph'].to(device)\n",
    "            spectra = batch['spectra'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            global_features = None\n",
    "            if 'global_features' in batch:\n",
    "                global_features = batch['global_features'].to(device)\n",
    "            \n",
    "            outputs = model(graph, spectra, global_features, task='cafa5')\n",
    "            probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
    "            \n",
    "            all_preds_prob.append(probs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds_prob = np.concatenate(all_preds_prob, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    # Compute F-max across different thresholds\n",
    "    logger.info(f\"\\nEvaluating F-max across thresholds...\")\n",
    "    \n",
    "    thresholds = np.arange(0.1, 0.95, 0.05)\n",
    "    f_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        preds_binary = (all_preds_prob > threshold).astype(int)\n",
    "        f_score = MetricComputer.f_max_score(all_preds_prob, all_labels)\n",
    "        f_scores.append(f_score)\n",
    "    \n",
    "    best_threshold_idx = np.argmax(f_scores)\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    best_f_max = f_scores[best_threshold_idx]\n",
    "    \n",
    "    logger.info(f\"Best F-max: {best_f_max:.4f} at threshold {best_threshold:.2f}\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: Evaluation skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot threshold sensitivity\n",
    "if dataset is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(thresholds, f_scores, marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "    ax.axvline(best_threshold, color='red', linestyle='--', linewidth=2, label=f'Best: {best_threshold:.2f}')\n",
    "    ax.set_xlabel('Classification Threshold', fontsize=12)\n",
    "    ax.set_ylabel('F-max Score', fontsize=12)\n",
    "    ax.set_title('F-max Score vs Classification Threshold', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    logger.info(f\"Threshold sensitivity plot shown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a6d76",
   "metadata": {},
   "source": [
    "## 9. Generate Competition Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390928b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset is not None:\n",
    "    logger.info(\"Generating test set predictions for submission...\")\n",
    "    \n",
    "    # Load test sequences\n",
    "    try:\n",
    "        df_test = pd.read_csv('./data/cafa5/test_sequences.fasta')\n",
    "        test_proteins = df_test['protein_id'].unique()\n",
    "        logger.info(f\"Test set size: {len(test_proteins)} proteins\")\n",
    "    except:\n",
    "        logger.warning(\"Could not load test sequences. Using dummy test set.\")\n",
    "        test_proteins = [f'test_protein_{i}' for i in range(100)]\n",
    "    \n",
    "    # Create submission file\n",
    "    submission_data = []\n",
    "    \n",
    "    for protein_id in test_proteins:\n",
    "        # In real scenario, would run model inference on each protein\n",
    "        # For demo, generate random predictions\n",
    "        predicted_probs = np.random.rand(num_go_terms)\n",
    "        \n",
    "        # Apply threshold\n",
    "        predicted_terms = np.where(predicted_probs > best_threshold if dataset is not None else 0.5)[0]\n",
    "        \n",
    "        # Convert indices to GO terms\n",
    "        go_terms = [idx_to_go.get(idx, f'GO:{idx:07d}') for idx in predicted_terms]\n",
    "        \n",
    "        submission_data.append({\n",
    "            'protein_id': protein_id,\n",
    "            'go_terms': ' '.join(go_terms) if go_terms else 'GO:0005575'  # Default to cellular_component\n",
    "        })\n",
    "    \n",
    "    df_submission = pd.DataFrame(submission_data)\n",
    "    df_submission.to_csv('./data/cafa5/submission.csv', index=False)\n",
    "    \n",
    "    logger.info(f\"Submission file created: {len(df_submission)} proteins\")\n",
    "    logger.info(f\"\\nSample predictions:\")\n",
    "    print(df_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec37ed6",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"CAFA 5 Competition Execution Summary\")\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(f\"Competition: CAFA 5 - Protein Function Prediction\")\n",
    "logger.info(f\"Task: Multi-label GO term prediction\")\n",
    "logger.info(f\"Metric: F-max score (optimized F1 across thresholds)\")\n",
    "logger.info(f\"Approach: Vibro-structural multimodal model\")\n",
    "logger.info(f\"\\nModel: VibroStructuralModel (Multi-label Head)\")\n",
    "logger.info(f\"  - GNN branch: Structural graph encoding\")\n",
    "logger.info(f\"  - CNN branch: Spectral fingerprint encoding\")\n",
    "logger.info(f\"  - Fusion: Bilinear transformation\")\n",
    "logger.info(f\"  - Head: Multi-label logistic regression ({num_go_terms} GO terms)\")\n",
    "logger.info(f\"\\nTraining Details:\")\n",
    "logger.info(f\"  - Loss: Weighted BCE (focal loss alternative available)\")\n",
    "logger.info(f\"  - Optimizer: Adam (lr=5e-4)\")\n",
    "logger.info(f\"  - Schedule: ReduceLROnPlateau (patience=5)\")\n",
    "logger.info(f\"  - Early stopping: patience=15\")\n",
    "logger.info(f\"\\nNext steps:\")\n",
    "logger.info(f\"  1. Download full CAFA 5 dataset\")\n",
    "logger.info(f\"  2. Retrieve 3D structures from AlphaFold DB\")\n",
    "logger.info(f\"  3. Precompute spectral features for all proteins\")\n",
    "logger.info(f\"  4. Implement hierarchical GO prediction (respecting ontology)\")\n",
    "logger.info(f\"  5. Train on full dataset (~30,000 proteins)\")\n",
    "logger.info(f\"  6. Optimize threshold for F-max metric\")\n",
    "logger.info(f\"  7. Ensemble with ESM-2 sequence embeddings\")\n",
    "logger.info(f\"  8. Generate final submission\")\n",
    "logger.info(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
