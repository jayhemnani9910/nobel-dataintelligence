{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187aca86",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54eb9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:36.685845Z",
     "iopub.status.busy": "2025-12-17T00:36:36.685535Z",
     "iopub.status.idle": "2025-12-17T00:36:38.520351Z",
     "shell.execute_reply": "2025-12-17T00:36:38.519816Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style('whitegrid')\n",
    "except ImportError:\n",
    "    sns = None\n",
    "import logging\n",
    "\n",
    "# Ensure repo root is on sys.path (works from repo root or notebooks/)\n",
    "repo_root = Path.cwd()\n",
    "if not (repo_root / 'src').exists():\n",
    "    repo_root = repo_root.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.data_acquisition import KaggleDataAcquisition\n",
    "from src.datasets import NovozymesDataset\n",
    "from src.models.multimodal import VibroStructuralModel\n",
    "from src.training import Trainer, MetricComputer\n",
    "from src.utils import Logger, set_seed, get_device, batch_collate_function\n",
    "\n",
    "logger = Logger.setup('QDD-Novozymes', level=logging.INFO)\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "data_kaggle_dir = repo_root / 'data' / 'kaggle'\n",
    "spectral_dir = repo_root / 'data' / 'spectral'\n",
    "checkpoints_dir = repo_root / 'checkpoints'\n",
    "data_kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "spectral_dir.mkdir(parents=True, exist_ok=True)\n",
    "checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info('Setup complete!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381cf360",
   "metadata": {},
   "source": [
    "## 2. Download and Explore Novozymes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958f33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.521794Z",
     "iopub.status.busy": "2025-12-17T00:36:38.521585Z",
     "iopub.status.idle": "2025-12-17T00:36:38.525888Z",
     "shell.execute_reply": "2025-12-17T00:36:38.525462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download competition data (requires kaggle CLI credentials)\n",
    "logger.info(\"Downloading Novozymes competition data...\")\n",
    "kaggle_acq = KaggleDataAcquisition(output_dir=str(data_kaggle_dir))\n",
    "\n",
    "# Note: Uncomment to download\n",
    "# train_csv, test_csv, struct_pdb = kaggle_acq.download_novozymes()\n",
    "\n",
    "# For this demo, check if files exist\n",
    "train_csv = data_kaggle_dir / 'train.csv'\n",
    "test_csv = data_kaggle_dir / 'test.csv'\n",
    "struct_pdb = data_kaggle_dir / 'wildtype_structure_prediction_af2.pdb'\n",
    "\n",
    "if not train_csv.exists():\n",
    "    logger.warning(\"Train data not found. Please run: kaggle competitions download -c novozymes-enzyme-stability-prediction -p ./data/kaggle\")\n",
    "else:\n",
    "    logger.info(\"Novozymes data found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abb5c4",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3088536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.526991Z",
     "iopub.status.busy": "2025-12-17T00:36:38.526880Z",
     "iopub.status.idle": "2025-12-17T00:36:38.542009Z",
     "shell.execute_reply": "2025-12-17T00:36:38.541626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training data (or fall back to a small demo dataset)\n",
    "if train_csv.exists():\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "else:\n",
    "    logger.warning(\"train.csv not found; using a demo dataset so the notebook can run end-to-end.\")\n",
    "    df_train = pd.DataFrame({\n",
    "        'seq_id': [f'demo_{i}' for i in range(200)],\n",
    "        'protein_sequence': ['ACDEFGHIKLMNPQRSTVWY' for _ in range(200)],\n",
    "        'pH': np.random.choice([6.0, 7.0, 8.0], size=200),\n",
    "        'tm': np.random.normal(loc=50.0, scale=5.0, size=200),\n",
    "    })\n",
    "    # Persist demo files so downstream cells can run unchanged\n",
    "    df_train.to_csv(train_csv, index=False)\n",
    "    if not test_csv.exists():\n",
    "        df_demo_test = df_train.drop(columns=['tm']).head(50)\n",
    "        df_demo_test.to_csv(test_csv, index=False)\n",
    "logger.info(f\"Training data shape: {df_train.shape}\")\n",
    "logger.info(f\"\\nFirst few rows:\")\n",
    "print(df_train.head())\n",
    "\n",
    "logger.info(f\"\\nData info:\")\n",
    "print(df_train.info())\n",
    "\n",
    "logger.info(f\"\\nTm statistics:\")\n",
    "print(df_train['tm'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f43b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.543355Z",
     "iopub.status.busy": "2025-12-17T00:36:38.543234Z",
     "iopub.status.idle": "2025-12-17T00:36:38.782755Z",
     "shell.execute_reply": "2025-12-17T00:36:38.782155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize Tm distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_train['tm'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Melting Temperature (°C)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Tm Values', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# By pH\n",
    "for ph in df_train['pH'].unique():\n",
    "    mask = df_train['pH'] == ph\n",
    "    axes[1].scatter(df_train[mask]['pH'], df_train[mask]['tm'], \n",
    "                   alpha=0.5, s=30, label=f'pH={ph}')\n",
    "axes[1].set_xlabel('pH', fontsize=12)\n",
    "axes[1].set_ylabel('Tm (°C)', fontsize=12)\n",
    "axes[1].set_title('Tm vs pH', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Data exploration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cce8fb",
   "metadata": {},
   "source": [
    "## 4. Precompute Spectral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1414d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.784077Z",
     "iopub.status.busy": "2025-12-17T00:36:38.783941Z",
     "iopub.status.idle": "2025-12-17T00:36:38.790293Z",
     "shell.execute_reply": "2025-12-17T00:36:38.789884Z"
    }
   },
   "outputs": [],
   "source": [
    "# For efficiency, precompute spectra for all mutations\n",
    "# In full implementation, would use mass-perturbation NMA\n",
    "\n",
    "logger.info(\"Precomputing spectral data...\")\n",
    "\n",
    "if struct_pdb.exists():\n",
    "    try:\n",
    "        # Load wildtype structure\n",
    "        import prody as pr\n",
    "        wt_structure = pr.parsePDB(str(struct_pdb))\n",
    "        logger.info(f\"Wildtype structure: {wt_structure.numResidues()} residues\")\n",
    "\n",
    "        # Compute WT spectrum (cached)\n",
    "        from src.nma_analysis import ANMAnalyzer\n",
    "        from src.spectral_generation import SpectralGenerator\n",
    "\n",
    "        anm = ANMAnalyzer(wt_structure, cutoff=15.0)\n",
    "        freqs, _ = anm.compute_modes(k=50)\n",
    "        s_vib = anm.compute_vibrational_entropy(k=50)\n",
    "\n",
    "        sg = SpectralGenerator(freq_min=0, freq_max=500, n_points=1000)\n",
    "        wt_spectrum = sg.generate_dos(freqs, broadening=5.0)\n",
    "\n",
    "        # Save for dataset loading\n",
    "        np.save(spectral_dir / 'wt_spectrum.npy', wt_spectrum)\n",
    "        logger.info(f\"WT spectrum saved. S_vib = {s_vib:.2f} J/(mol·K)\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"WT spectrum precompute failed: {e}\")\n",
    "        logger.info(\"Using synthetic spectrum\")\n",
    "        np.save(spectral_dir / 'wt_spectrum.npy', np.random.randn(1000))\n",
    "else:\n",
    "    logger.warning(\"Wildtype structure not found. Using synthetic spectra.\")\n",
    "    np.save(spectral_dir / 'wt_spectrum.npy', np.random.randn(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1d581",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8b2fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.791547Z",
     "iopub.status.busy": "2025-12-17T00:36:38.791426Z",
     "iopub.status.idle": "2025-12-17T00:36:38.799786Z",
     "shell.execute_reply": "2025-12-17T00:36:38.799363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Novozymes dataset\n",
    "logger.info(\"Creating Novozymes dataset...\")\n",
    "\n",
    "try:\n",
    "    dataset = NovozymesDataset(\n",
    "        csv_file=str(train_csv),\n",
    "        structure_file=str(struct_pdb),\n",
    "        spectra_dir=str(spectral_dir),\n",
    "        include_updates=True\n",
    "    )\n",
    "    logger.info(f\"Dataset created: {len(dataset)} samples\")\n",
    "except:\n",
    "    logger.warning(\"Novozymes dataset creation failed. Using dummy dataset for demo.\")\n",
    "    # Create dummy dataset for demonstration\n",
    "    dataset = None\n",
    "\n",
    "if dataset is not None:\n",
    "    # Split into train/val/test (robust for small demo datasets)\n",
    "    n_total = len(dataset)\n",
    "    train_size = max(1, int(0.7 * n_total))\n",
    "    val_size = max(1, int(0.15 * n_total))\n",
    "    test_size = n_total - train_size - val_size\n",
    "    if test_size < 1:\n",
    "        test_size = 1\n",
    "        train_size = max(1, n_total - val_size - test_size)\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Split: train={train_size}, val={val_size}, test={test_size}\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=batch_collate_function,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=batch_collate_function,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=batch_collate_function,\n",
    "    )\n",
    "    \n",
    "    logger.info(\"DataLoaders created successfully!\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: skipping DataLoader creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7841bb",
   "metadata": {},
   "source": [
    "## 6. Initialize Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c10e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:38.800832Z",
     "iopub.status.busy": "2025-12-17T00:36:38.800728Z",
     "iopub.status.idle": "2025-12-17T00:36:40.691668Z",
     "shell.execute_reply": "2025-12-17T00:36:40.691270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "logger.info(\"Initializing Vibro-Structural model...\")\n",
    "\n",
    "model = VibroStructuralModel(\n",
    "    latent_dim=128,\n",
    "    gnn_input_dim=24,\n",
    "    fusion_type='bilinear',\n",
    "    dropout=0.2,\n",
    "    num_go_terms=10000  # Not used for Novozymes\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Model: {total_params:,} total parameters, {trainable_params:,} trainable\")\n",
    "\n",
    "# Setup training\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "try:\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "except TypeError:\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "loss_fn = nn.MSELoss()  # L2 loss for regression\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    checkpoint_dir=str(checkpoints_dir)\n",
    ")\n",
    "\n",
    "logger.info(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2550bc",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16236545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:40.693207Z",
     "iopub.status.busy": "2025-12-17T00:36:40.692980Z",
     "iopub.status.idle": "2025-12-17T00:36:53.187758Z",
     "shell.execute_reply": "2025-12-17T00:36:53.187421Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train model (requires actual dataset)\n",
    "if dataset is not None:\n",
    "    logger.info(\"Starting training...\")\n",
    "    \n",
    "    best_loss = trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        epochs=10,\n",
    "        metric_fn=MetricComputer.spearman_correlation,\n",
    "        early_stopping_patience=5,\n",
    "        task='novozymes'\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"\\nTraining complete! Best validation loss: {best_loss:.4f}\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: Training skipped. Use actual Novozymes data to train.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b1863",
   "metadata": {},
   "source": [
    "## 8. Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c19448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:53.189293Z",
     "iopub.status.busy": "2025-12-17T00:36:53.189049Z",
     "iopub.status.idle": "2025-12-17T00:36:53.224799Z",
     "shell.execute_reply": "2025-12-17T00:36:53.224163Z"
    }
   },
   "outputs": [],
   "source": [
    "if dataset is not None:\n",
    "    logger.info(\"Evaluating on test set...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            graph = batch['graph'].to(device)\n",
    "            spectra = batch['spectra'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            global_features = None\n",
    "            if 'global_features' in batch:\n",
    "                global_features = batch['global_features'].to(device)\n",
    "            \n",
    "            outputs = model(graph, spectra, global_features, task='novozymes')\n",
    "            \n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds, axis=0).squeeze()\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    # Compute metrics\n",
    "    spearman = MetricComputer.spearman_correlation(all_preds, all_labels)\n",
    "    mae = MetricComputer.mean_absolute_error(all_preds, all_labels)\n",
    "    mse = MetricComputer.mean_squared_error(all_preds, all_labels)\n",
    "    \n",
    "    logger.info(f\"\\nTest Set Metrics:\")\n",
    "    logger.info(f\"  Spearman Correlation: {spearman:.4f}\")\n",
    "    logger.info(f\"  MAE: {mae:.4f}\")\n",
    "    logger.info(f\"  MSE: {mse:.4f}\")\n",
    "\n",
    "    # Generate Kaggle-style submission for test.csv (if present)\n",
    "    if test_csv.exists():\n",
    "        logger.info(\"Generating submission predictions for test.csv...\")\n",
    "        df_test = pd.read_csv(test_csv)\n",
    "        test_dataset = NovozymesDataset(\n",
    "            csv_file=str(test_csv),\n",
    "            structure_file=str(struct_pdb),\n",
    "            spectra_dir=str(spectral_dir),\n",
    "            include_updates=False,\n",
    "        )\n",
    "        test_loader_submit = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            collate_fn=batch_collate_function,\n",
    "        )\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader_submit:\n",
    "                graph = batch['graph'].to(device)\n",
    "                spectra = batch['spectra'].to(device)\n",
    "                global_features = batch.get('global_features')\n",
    "                if global_features is not None:\n",
    "                    global_features = global_features.to(device)\n",
    "                out = model(graph, spectra, global_features, task='novozymes').squeeze(-1)\n",
    "                preds.append(out.cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        submission = pd.DataFrame({'seq_id': df_test['seq_id'].values, 'tm': preds})\n",
    "        out_path = data_kaggle_dir / 'submission.csv'\n",
    "        submission.to_csv(out_path, index=False)\n",
    "        logger.info(f\"Saved submission: {out_path}\")\n",
    "else:\n",
    "    logger.info(\"Demo mode: Evaluation skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ededa",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe90774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T00:36:53.226108Z",
     "iopub.status.busy": "2025-12-17T00:36:53.225959Z",
     "iopub.status.idle": "2025-12-17T00:36:53.240220Z",
     "shell.execute_reply": "2025-12-17T00:36:53.239790Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"Novozymes Competition Execution Summary\")\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(f\"Competition: Novozymes Enzyme Stability Prediction\")\n",
    "logger.info(f\"Task: Predict melting temperature (Tm) from structure\")\n",
    "logger.info(f\"Metric: Spearman rank correlation\")\n",
    "logger.info(f\"Approach: Vibro-structural multimodal model\")\n",
    "logger.info(f\"\\nModel: VibroStructuralModel\")\n",
    "logger.info(f\"  - GNN branch: Structural graph encoding\")\n",
    "logger.info(f\"  - CNN branch: Spectral fingerprint encoding\")\n",
    "logger.info(f\"  - Fusion: Bilinear transformation\")\n",
    "logger.info(f\"  - Head: Regression MLP for Tm prediction\")\n",
    "logger.info(f\"\\nNext steps:\")\n",
    "logger.info(f\"  1. Download full Novozymes dataset\")\n",
    "logger.info(f\"  2. Precompute all mutation spectra (mass-perturbation NMA)\")\n",
    "logger.info(f\"  3. Implement mutation-specific delta features\")\n",
    "logger.info(f\"  4. Train on full dataset (4,000+ mutations)\")\n",
    "logger.info(f\"  5. Evaluate with Spearman correlation\")\n",
    "logger.info(f\"  6. Generate test set predictions\")\n",
    "logger.info(f\"  7. Submit to Kaggle competition\")\n",
    "logger.info(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
